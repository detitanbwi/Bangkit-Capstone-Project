{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6g993Gb36ET7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSz24y1ndxTG",
        "outputId": "76ba3da6-3fce-4872-98d5-ba088f15781b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset"
      ],
      "metadata": {
        "id": "0RI1ZgJFd0jZ"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load data from Excel files\n",
        "def excel_to_df(excel):\n",
        "    df = pd.read_excel(excel, index_col='index')\n",
        "    return df"
      ],
      "metadata": {
        "id": "cl8o96Zxd3KM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "CNN= '/content/dataset_cnn.xlsx'\n",
        "KOMPAS= '/content/dataset_kompas.xlsx'\n",
        "TEMPO= '/content/dataset_tempo.xlsx'\n",
        "TURNBACKHOAX= '/content/dataset_turnbackhoax.xlsx'\n",
        "\n",
        "df_cnn = excel_to_df(CNN)\n",
        "df_kompas = excel_to_df(KOMPAS)\n",
        "df_tempo = excel_to_df(TEMPO)\n",
        "df_turnbackhoax = excel_to_df(TURNBACKHOAX)"
      ],
      "metadata": {
        "id": "PYzXGa_ud6GC"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess data\n",
        "def preprocess_text(text):\n",
        "    text = str(text)\n",
        "    text = re.sub(r'http\\S+', '', text)  # Remove URLs\n",
        "    text = re.sub(r'@[^\\s]+', '', text)  # Remove usernames\n",
        "    text = re.sub(r'#', '', text)  # Remove hashtags\n",
        "    text = re.sub(r'RT[\\s]+', '', text)  # Remove retweets\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(' +', ' ', text)  # Remove extra spaces\n",
        "    return text"
      ],
      "metadata": {
        "id": "0VcAgrR0d-5M"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply preprocessing\n",
        "df_cnn['cleaned'] = df_cnn['cleaned'].apply(preprocess_text)\n",
        "df_kompas['cleaned'] = df_kompas['cleaned'].apply(preprocess_text)\n",
        "df_tempo['cleaned'] = df_tempo['cleaned'].apply(preprocess_text)\n",
        "df_turnbackhoax['cleaned'] = df_turnbackhoax['cleaned'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "N__Dh039eA-I"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate datasets\n",
        "df_combined = pd.concat([df_cnn, df_kompas, df_tempo, df_turnbackhoax], ignore_index=True)"
      ],
      "metadata": {
        "id": "xAMiW6DyeCsH"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into training and testing sets\n",
        "train_df, test_df = train_test_split(df_combined, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "v2JtGhF4d67S"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and create datasets\n",
        "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
        "X_train = vectorizer.fit_transform(train_df['cleaned']).toarray()\n",
        "X_test = vectorizer.transform(test_df['cleaned']).toarray()\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(train_df['label'])\n",
        "y_test = label_encoder.transform(test_df['label'])"
      ],
      "metadata": {
        "id": "c93irGi4eJqY"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build and compile the Sequential model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(1000,)),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "wB85jd1VeKyI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "batch_size = 8\n",
        "epochs = 5\n",
        "\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=epochs,\n",
        "    validation_data=(X_test, y_test),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sQyJL-AeN08",
        "outputId": "4f7b237d-b862-40e0-83d1-7b89f34c8178"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "3134/3134 [==============================] - 13s 4ms/step - loss: 0.1177 - accuracy: 0.9666 - val_loss: 0.0606 - val_accuracy: 0.9820\n",
            "Epoch 2/5\n",
            "3134/3134 [==============================] - 13s 4ms/step - loss: 0.0556 - accuracy: 0.9831 - val_loss: 0.0559 - val_accuracy: 0.9824\n",
            "Epoch 3/5\n",
            "3134/3134 [==============================] - 13s 4ms/step - loss: 0.0453 - accuracy: 0.9862 - val_loss: 0.0575 - val_accuracy: 0.9831\n",
            "Epoch 4/5\n",
            "3134/3134 [==============================] - 13s 4ms/step - loss: 0.0332 - accuracy: 0.9901 - val_loss: 0.0625 - val_accuracy: 0.9834\n",
            "Epoch 5/5\n",
            "3134/3134 [==============================] - 13s 4ms/step - loss: 0.0276 - accuracy: 0.9917 - val_loss: 0.0769 - val_accuracy: 0.9821\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d5e00a54f70>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4pEaI_BeQs0",
        "outputId": "70f7b539-28cd-41c1-f3a8-46f94be8a9fe"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "196/196 [==============================] - 0s 2ms/step - loss: 0.0769 - accuracy: 0.9821\n",
            "Test Accuracy: 0.9821286201477051\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    \"Slogan Pemerintahan sekarang Koalisi Indonesia Hebat\",\n",
        "    \"Jokowi Ajak Masyarakat Hadapi 2022 dengan Semangat Baru commerce, misalnya, mencapai nilai 24,8 miliar dolar AS tahun ini\"\n",
        "]"
      ],
      "metadata": {
        "id": "sneEhuNRdpi2"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess teks\n",
        "preprocessed_texts = [preprocess_text(text) for text in texts]"
      ],
      "metadata": {
        "id": "7GEX-K_ffNvC"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize teks menggunakan CountVectorizer\n",
        "X_pred = vectorizer.transform(preprocessed_texts).toarray()"
      ],
      "metadata": {
        "id": "tO62vx2FfRcc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lakukan prediksi\n",
        "predictions = model.predict(X_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4oh0nLOfTQs",
        "outputId": "7d149773-2128-46ce-d5ab-a731dc9b36f5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 62ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Konversi prediksi menjadi label\n",
        "predicted_labels = [1 if prediction > 0.5 else 0 for prediction in predictions]"
      ],
      "metadata": {
        "id": "q5n6MFg4fU-5"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode label menggunakan label_encoder\n",
        "decoded_labels = label_encoder.inverse_transform(predicted_labels)"
      ],
      "metadata": {
        "id": "gxpTUFs7fbtg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tampilkan hasil prediksi\n",
        "for text, label in zip(texts, decoded_labels):\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Predicted Label: {label}\")\n",
        "    print(\"------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJobyIdIfdix",
        "outputId": "98c2a6f7-16a7-45f8-b2cc-2ea59628b108"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text: Slogan Pemerintahan sekarang Koalisi Indonesia Hebat\n",
            "Predicted Label: 1\n",
            "------------\n",
            "Text: Jokowi Ajak Masyarakat Hadapi 2022 dengan Semangat Baru commerce, misalnya, mencapai nilai 24,8 miliar dolar AS tahun ini\n",
            "Predicted Label: 0\n",
            "------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the entire model in the .h5 format\n",
        "model.save(\"hoax_detection_model.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-fZ9p61gM6g",
        "outputId": "99cb1e08-dfb2-46f2-a8a5-832ffbe5ea87"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}